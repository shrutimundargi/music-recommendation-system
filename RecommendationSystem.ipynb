{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "EEFOVzMu3MR9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzT1nhWt2cdw"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyspark.sql.functions import year"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "        .appName(\"data_prep\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "id": "ecZrj_4-2e6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import types"
      ],
      "metadata": {
        "id": "wzKwdpWQ2hOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = types.StructType([\n",
        "    types.StructField('id', types.StringType(), True),\n",
        "    types.StructField('name', types.StringType(), True),\n",
        "    types.StructField('popularity', types.IntegerType(), True),\n",
        "    types.StructField('duration_ms', types.IntegerType(), True),\n",
        "    types.StructField('explicit', types.IntegerType(), True),\n",
        "    types.StructField('artists', types.StringType(), True),\n",
        "    types.StructField('id_artists',types.StringType(), True),\n",
        "    types.StructField('release_date', types.DateType(), True),\n",
        "    types.StructField('danceability', types.DoubleType(), True),\n",
        "    types.StructField('energy', types.DoubleType(), True),\n",
        "    types.StructField('key', types.IntegerType(), True),\n",
        "    types.StructField('loudness', types.DoubleType(), True),\n",
        "    types.StructField('mode', types.IntegerType(), True),\n",
        "    types.StructField('speechiness', types.DoubleType(), True),\n",
        "    types.StructField('acousticness', types.DoubleType(), True),\n",
        "    types.StructField('instrumentalness', types.DoubleType(), True),\n",
        "    types.StructField('liveness', types.DoubleType(), True),\n",
        "    types.StructField('valence', types.DoubleType(), True),\n",
        "    types.StructField('tempo', types.DoubleType(), True),\n",
        "    types.StructField('time_signature', types.IntegerType(), True)\n",
        "])"
      ],
      "metadata": {
        "id": "heqaziJs2jsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tracks_sparkdf=spark.read.option(\"header\",\"true\").schema(schema).csv(\"tracks.csv\")"
      ],
      "metadata": {
        "id": "gBzEc7oO2mjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extra pre-processing:\n",
        "from pyspark.sql.functions import regexp_replace, trim\n",
        "# remove the square brackets, single quotes and commas\n",
        "# remove the unwanted characters\n",
        "tracks_sparkdf = tracks_sparkdf.withColumn(\"artists_array\", trim(regexp_replace(tracks_sparkdf[\"id_artists\"], \"[\\[\\]' ]\", \"\")))\n",
        "\n",
        "# trim any whitespace characters\n",
        "#tracks_sparkdf = tracks_sparkdf.withColumn(\"artists_array\", trim(tracks_sparkdf[\"artists_array\"]))"
      ],
      "metadata": {
        "id": "2VEa7AL_2oSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Casting iString to Array of Strings for the Spark DF\n",
        "from pyspark.sql.functions import split\n",
        "\n",
        "# assuming your csv file has been loaded into a dataframe called \"df\"\n",
        "#overwrite the same column\n",
        "tracks_sparkdf = tracks_sparkdf.withColumn(\"artists_array\", split(tracks_sparkdf[\"artists_array\"], \",\"))"
      ],
      "metadata": {
        "id": "qdDSxNw02sNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tracks_sparkdf=tracks_sparkdf.withColumnRenamed(\"name\",\"song_name\")\n",
        "\n",
        "tracks_sparkdf=tracks_sparkdf.withColumnRenamed(\"popularity\",\"song_popularity\")\n",
        "\n",
        "# show the resulting dataframe\n",
        "tracks_sparkdf.printSchema()"
      ],
      "metadata": {
        "id": "hLBcBBYP2wXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artist_schema=types.StructType([\n",
        "    types.StructField('id', types.StringType(), True),\n",
        "    types.StructField('followers', types.DoubleType(), True),\n",
        "    types.StructField('genres', types.StringType(), True),\n",
        "    types.StructField('name', types.StringType(), True),\n",
        "    types.StructField('popularity', types.IntegerType(), True)\n",
        "])"
      ],
      "metadata": {
        "id": "6fW2JI5y2zbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artists_sparkdf=spark.read.option(\"header\",\"true\").schema(artist_schema).csv(\"artists.csv\")"
      ],
      "metadata": {
        "id": "F-Cx5hyd21xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rename \"name\" as \"artist_name\"\n",
        "\n",
        "artists_sparkdf=artists_sparkdf.withColumnRenamed(\"name\",\"artist_name\")\n",
        "\n",
        "artists_sparkdf=artists_sparkdf.withColumnRenamed(\"popularity\",\"artist_popularity\")"
      ],
      "metadata": {
        "id": "bqv_MCvD24HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# joining the two data sets:\n",
        "from pyspark.sql.functions import explode, col, struct\n",
        "\n",
        "\n",
        "# Step 1: Explode the id_artists column in the tracks dataframe\n",
        "exploded_tracks_df = tracks_sparkdf.selectExpr(\"*\", \"explode(artists_array) as artist_id\")"
      ],
      "metadata": {
        "id": "8VrZqkkJ24qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Rename the id column in the artists dataframe\n",
        "artists_df = artists_sparkdf.withColumnRenamed(\"id\", \"artist_id\")"
      ],
      "metadata": {
        "id": "tK0N7Jxj27qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Join the exploded tracks dataframe with the artists dataframe\n",
        "joined_df = exploded_tracks_df.join(artists_df, \"artist_id\")"
      ],
      "metadata": {
        "id": "O7zPFLqM2-Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#final step of data prep is claening and exploding the genres column\n",
        "#extra pre-processing:\n",
        "from pyspark.sql.functions import regexp_replace, trim\n",
        "# remove the square brackets, single quotes and commas\n",
        "# remove the unwanted characters\n",
        "joined_df = joined_df.withColumn(\"genres_array\", trim(regexp_replace(joined_df[\"genres\"], \"[\\[\\]' ]\", \"\")))\n",
        "#Casting iString to Array of Strings for the Spark DF\n",
        "from pyspark.sql.functions import split\n",
        "\n",
        "# assuming your csv file has been loaded into a dataframe called \"df\"\n",
        "#overwrite the same column\n",
        "joined_df = joined_df.withColumn(\"genres_array\", split(joined_df[\"genres_array\"], \",\"))\n",
        "#explode the column\n",
        "final_df = joined_df.selectExpr(\"*\", \"explode(genres_array) as genre_list\")"
      ],
      "metadata": {
        "id": "JSwjRz653AN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets modify the new df to fit our needs..we dont need so many rows..we just need all genre info in 1 list\n",
        "from pyspark.sql.functions import collect_list\n",
        "\n",
        "# Assume the DataFrame is called `song_data` and the ID column is called `song_id`\n",
        "grouped_data = final_df.groupBy('id', 'song_name', 'song_popularity', 'duration_ms', 'explicit','release_date', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
        "                                'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'artists') \\\n",
        "                       .agg(collect_list('genre_list').alias('genres'))\n"
      ],
      "metadata": {
        "id": "_N6O9nBM3Ea4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_data.printSchema()"
      ],
      "metadata": {
        "id": "PHKRpkkO3HF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Further Data Processing"
      ],
      "metadata": {
        "id": "5Yfax6aE3ST5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_data.columns"
      ],
      "metadata": {
        "id": "w4EbF2mL3Z24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, count, isnan, when\n",
        "\n",
        "# Check the number of rows and columns in the DataFrame\n",
        "print(\"Number of rows: \", grouped_data.count())\n",
        "print(\"Number of columns: \", len(grouped_data.columns))"
      ],
      "metadata": {
        "id": "NA58n2nB3JV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null values in each column\n",
        "grouped_data.select([count(when(col(c).isNull(), c)).alias(c) for c in grouped_data.columns]).show()\n",
        "\n",
        "grouped_data = grouped_data.withColumn('year', year(grouped_data['release_date']))\n",
        "\n",
        "grouped_data.printSchema()"
      ],
      "metadata": {
        "id": "3xLb85Yf3aKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Feature Analysis and Selection"
      ],
      "metadata": {
        "id": "zWuwxOu23dIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#EDA TO get feature\n",
        "pandas_df=grouped_data.toPandas()\n",
        "\n",
        "pandas_df.columns"
      ],
      "metadata": {
        "id": "Pgxi_jqb3fs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4_c6JtW63k3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the audio features from the DataFrame\n",
        "audio_features = ['song_popularity','explicit', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
        "                  'speechiness', 'acousticness',\n",
        "                  'instrumentalness', 'liveness',\n",
        "                  'valence','tempo','year']\n",
        "\n",
        "audio_df = pandas_df[audio_features]\n",
        "\n",
        "\n",
        "\n",
        "#Pearson's Correlation methord\n",
        "corr = audio_df.corr(method='pearson')\n",
        "# Plot heatmap\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(corr,xticklabels=audio_df.columns,yticklabels=audio_df.columns,annot=True,ax=ax)"
      ],
      "metadata": {
        "id": "ezCLFaar3mr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML PART"
      ],
      "metadata": {
        "id": "j6ZqiTuS3p0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fuzzy C Means"
      ],
      "metadata": {
        "id": "LOHQn41T3rim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "from skfuzzy.cluster import cmeans\n",
        "from numpy.lib.function_base import kaiser\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import plotly.express as px\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import pickle\n",
        "import time"
      ],
      "metadata": {
        "id": "1t5n4-Uy3uUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the most optimal number of cluster"
      ],
      "metadata": {
        "id": "PVB2lvld36ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "#audio_df = audio_df.values\n",
        "data = scaler.fit_transform(audio_df)\n",
        "k_range = range(10, 30)\n",
        "fcm_results = []\n",
        "for k in k_range:\n",
        "    print(\"On \",k)\n",
        "    cntr, u, u0, d, jm, p, fpc = cmeans(data.T, k, 2, error=0.005, maxiter=1000, init=None)\n",
        "    fcm_results.append({\n",
        "        'k': k,\n",
        "        'cntr': cntr,\n",
        "        'u': u,\n",
        "        'u0': u0,\n",
        "        'd': d,\n",
        "        'jm': jm,\n",
        "        'p': p,\n",
        "        'fpc': fpc\n",
        "    })\n",
        "fpc_values = [result['fpc'] for result in fcm_results]\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(k_range, fpc_values)\n",
        "ax.set_xlabel('Number of Clusters (k)')\n",
        "ax.set_ylabel('Fuzzy Partition Coefficient (FPC)')\n",
        "plt.show()\n",
        "# Find the optimal number of clusters\n",
        "diffs = np.diff([result['fpc'] for result in fcm_results])\n",
        "diffs2 = np.diff(diffs)\n",
        "k_opt = k_range[np.argmin(diffs2)+1]\n",
        "print(\"Optimal number of clusters:\", k_opt)"
      ],
      "metadata": {
        "id": "9FTwIx6k34wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df = (audio_df - audio_df.mean()) /audio_df.std()\n",
        "# Calculate WCSS for different values of k\n",
        "wcss = []\n",
        "for k in range(10, 30):\n",
        "    print(\"On \", k)\n",
        "    kmeans = KMeans(n_clusters=k, n_init=10,random_state=42)\n",
        "    kmeans.fit(scaled_df)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the WCSS values against k\n",
        "plt.plot(range(10, 30), wcss)\n",
        "plt.xlabel('Number of clusters (k)')\n",
        "plt.ylabel('WCSS')\n",
        "plt.title('Elbow Method')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I-zuP83v3-oN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df = StandardScaler().fit_transform(pandas_df.select_dtypes(np.number))\n",
        "n_clusters = range(25,35)\n",
        "gmm_bics = []\n",
        "for k in n_clusters:\n",
        "    gmm = GaussianMixture(n_components=k)\n",
        "    print(f\"On {k}\")\n",
        "    gmm.fit(scaled_df)\n",
        "    gmm_bics.append(gmm.bic(scaled_df))\n",
        "\n",
        "plt.plot(n_clusters, gmm_bics)\n",
        "plt.xlabel('Number of clusters (k)')\n",
        "plt.ylabel('BIC score')\n",
        "plt.title('Bayesian Information Criterion (BIC)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OX8dh3nu4BG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_n_clusters"
      ],
      "metadata": {
        "id": "hin4sOGI4D8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating models using the optimal number of clusters"
      ],
      "metadata": {
        "id": "Sm1Ixxl34T9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fuzzy C-Means"
      ],
      "metadata": {
        "id": "362kW-hC4W_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "pandas_df_fuzzy = pandas_df\n",
        "X = pandas_df_fuzzy.select_dtypes(np.number)\n",
        "cntr, u, u0, d, jm, p, fpc = cmeans(X.T, 21, 2, error=0.005, maxiter=1000, init=None)\n",
        "fcm_cluster_labels = np.argmax(u, axis=0)\n",
        "pandas_df_fuzzy['cluster_label'] = fcm_cluster_labels\n",
        "end_time = time.time()\n",
        "durationF = end_time - start_time\n",
        "np.save('fcm_model_cntr.npy', cntr)"
      ],
      "metadata": {
        "id": "ubGoD7_n4GJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## K-Means"
      ],
      "metadata": {
        "id": "w9QnaSUm4dCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "k_pipeline = Pipeline([('scaler', StandardScaler()),\n",
        "                                  ('kmeans', KMeans(n_clusters=20, verbose=2))])\n",
        "pandas_df_k = pandas_df\n",
        "X1 = pandas_df_k.select_dtypes(np.number)\n",
        "number_cols = list(X1.columns)\n",
        "k_labels = k_pipeline.fit_predict(X1)\n",
        "pandas_df_k['cluster_label'] = k_labels\n",
        "end_time = time.time()\n",
        "durationK = end_time - start_time"
      ],
      "metadata": {
        "id": "BaKnDSJb4al8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gaussian Mixture Model"
      ],
      "metadata": {
        "id": "1he6cnw04gsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "gmm_pipeline = Pipeline([('scaler', StandardScaler()),\n",
        "                             ('gmm', GaussianMixture(n_components=29))])\n",
        "\n",
        "pandas_df_gmm = pandas_df\n",
        "gmm_pipeline.fit(pandas_df_gmm.select_dtypes(np.number))\n",
        "labels = gmm_pipeline.predict(pandas_df_gmm.select_dtypes(np.number))\n",
        "pandas_df_gmm['cluster_label'] = labels\n",
        "end_time = time.time()\n",
        "durationG = end_time - start_time"
      ],
      "metadata": {
        "id": "QapX012y4jat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing clusters"
      ],
      "metadata": {
        "id": "XTKS7u_d4pAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def VisualizeClustersFCM(pandas_df_fuzzy):\n",
        "    pca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2))])\n",
        "    song_embedding = pca_pipeline.fit_transform(X)\n",
        "    projection = pd.DataFrame(columns=['x', 'y'], data=song_embedding)\n",
        "    projection['title'] = pandas_df['song_name']\n",
        "    projection['cluster'] = pandas_df_fuzzy['cluster_label']\n",
        "    fig = px.scatter(projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'title'])\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "3SGR0DNX4mM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def VisualizeClustersK(pandas_df_k):\n",
        "    pca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2))])\n",
        "    song_embedding = pca_pipeline.fit_transform(X)\n",
        "    projection = pd.DataFrame(columns=['x', 'y'], data=song_embedding)\n",
        "    projection['title'] = pandas_df['song_name']\n",
        "    projection['cluster'] = pandas_df_k['cluster_label']\n",
        "    fig = px.scatter(projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'title'])\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "ZmeolQ0s4u_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def VisualizeClustersGMM(pandas_df_gmm):\n",
        "    pca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2))])\n",
        "    song_embedding = pca_pipeline.fit_transform(X)\n",
        "    projection = pd.DataFrame(columns=['x', 'y'], data=song_embedding)\n",
        "    projection['title'] = pandas_df['song_name']\n",
        "    projection['cluster'] = pandas_df_gmm['cluster_label']\n",
        "    fig = px.scatter(projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'title'])\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "u4HJQ2YN4xSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fuzzy C-Means"
      ],
      "metadata": {
        "id": "NSMg6iM04zaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VisualizeClustersFCM(pandas_df_fuzzy)"
      ],
      "metadata": {
        "id": "WsuTPRQk46q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Means"
      ],
      "metadata": {
        "id": "CcPkrWQ441o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VisualizeClustersK(pandas_df_k)"
      ],
      "metadata": {
        "id": "SVMND83t481L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gaussian Mixture Model"
      ],
      "metadata": {
        "id": "8XYsjdwD45DJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VisualizeClustersGMM(pandas_df_gmm)"
      ],
      "metadata": {
        "id": "brFyeU0y5B5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Song Recommendations"
      ],
      "metadata": {
        "id": "bvAnrKEp5Jlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#first step lets use spotify api:\n",
        "import spotipy\n",
        "import os\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "from collections import defaultdict\n",
        "\n",
        "cid = 'beb46a274d9841269ee7e457607c09e7'\n",
        "secret = '17caa1a20c5e470b9e0757e539660e5d'\n",
        "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
        "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
        "\n",
        "\n",
        "def get_song_realtime(song_name,year):\n",
        "\n",
        "    song_data = defaultdict()\n",
        "    results = sp.search(q= 'track: {} year: {}'.format(song_name,\n",
        "                                                       year), limit=1)\n",
        "    if results['tracks']['items'] == []:\n",
        "        return None\n",
        "\n",
        "    results = results['tracks']['items'][0]\n",
        "\n",
        "    track_id = results['id']\n",
        "    audio_features = sp.audio_features(track_id)[0]\n",
        "\n",
        "    song_data['song_name'] = [song_name]\n",
        "    song_data['year'] = [year]\n",
        "    song_data['explicit'] = [int(results['explicit'])]\n",
        "    song_data['duration_ms'] = [results['duration_ms']]\n",
        "    song_data['song_popularity'] = [results['popularity']]\n",
        "\n",
        "    for key, value in audio_features.items():\n",
        "        song_data[key] = value\n",
        "\n",
        "    return pd.DataFrame(song_data)\n",
        "\n",
        "from collections import defaultdict\n",
        "from scipy.spatial.distance import cdist\n",
        "import difflib\n",
        "\n",
        "number_cols = ['song_popularity',\n",
        " 'duration_ms',\n",
        " 'explicit',\n",
        " 'danceability',\n",
        " 'energy',\n",
        " 'key',\n",
        " 'loudness',\n",
        " 'mode',\n",
        " 'speechiness',\n",
        " 'acousticness',\n",
        " 'instrumentalness',\n",
        " 'liveness',\n",
        " 'valence',\n",
        " 'tempo',\n",
        " 'time_signature','year']\n",
        "\n",
        "def song_information(song, pandas_df):\n",
        "    try:\n",
        "        song_data = pandas_df[(pandas_df['song_name'] == song['song_name'])\n",
        "                                & (pandas_df['year'] == song['year'])].iloc[0]\n",
        "        return song_data\n",
        "\n",
        "    except IndexError:\n",
        "        return get_song_realtime(song['song_name'], song['year'])\n",
        "\n",
        "\n",
        "def find_mean(song_list, pandas_df):\n",
        "\n",
        "    song_vectors = []\n",
        "\n",
        "    for song in song_list:\n",
        "        song_data = song_information(song, pandas_df)\n",
        "        if song_data is None:\n",
        "            print('Warning: {} does not exist in Spotify or in database'.format(song['name']))\n",
        "            continue\n",
        "        song_vector = song_data[number_cols].values\n",
        "        song_vectors.append(song_vector)\n",
        "\n",
        "    song_matrix = np.array(list(song_vectors))\n",
        "    return np.mean(song_matrix, axis=0)\n",
        "\n",
        "def dictionary_list(dict_list):\n",
        "\n",
        "    flattened_dict = defaultdict()\n",
        "    for key in dict_list[0].keys():\n",
        "        flattened_dict[key] = []\n",
        "\n",
        "    for dictionary in dict_list:\n",
        "        for key, value in dictionary.items():\n",
        "            flattened_dict[key].append(value)\n",
        "\n",
        "    return flattened_dict\n",
        "\n",
        "def recommend_songs_FuzzyC(song_list, pandas_df, n_songs=10):\n",
        "\n",
        "    #pandas_df = pandas_df[pandas_df['year'] > 2000]\n",
        "    metadata_cols = ['song_name', 'artists','cluster_label', 'song_popularity',\n",
        " 'danceability',\n",
        " 'acousticness',\n",
        " 'instrumentalness',\n",
        " 'valence',\n",
        " 'tempo']\n",
        "    song_dict = dictionary_list(song_list)\n",
        "\n",
        "    song_center = find_mean(song_list, pandas_df)\n",
        "    scaler = MinMaxScaler()\n",
        "    #pandas_df = pandas_df[pandas_df['year'] >= 2010]\n",
        "    scaled_data = scaler.fit_transform(pandas_df[number_cols])\n",
        "    scaled_song_center = scaler.transform(song_center.reshape(1, -1))\n",
        "    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n",
        "    index = list(np.argsort(distances)[:, :n_songs][0])\n",
        "\n",
        "    rec_songs = pandas_df.iloc[index]\n",
        "    rec_songs = rec_songs[~rec_songs['song_name'].isin(song_dict['song_name'])]\n",
        "\n",
        "\n",
        "    return rec_songs[metadata_cols].to_dict(orient='records')\n",
        "\n",
        "def recommend_songs_Kmeans(song_list, pandas_df, n_songs=10):\n",
        "\n",
        "    metadata_cols = ['song_name', 'artists','cluster_label', 'song_popularity',\n",
        " 'danceability',\n",
        " 'acousticness',\n",
        " 'instrumentalness',\n",
        " 'valence',\n",
        " 'tempo']\n",
        "    song_dict = dictionary_list(song_list)\n",
        "\n",
        "    song_center = find_mean(song_list, pandas_df)\n",
        "    scaler = k_pipeline.steps[0][1]\n",
        "    scaled_data = scaler.fit_transform(pandas_df[number_cols])\n",
        "    scaled_song_center = scaler.transform(song_center.reshape(1, -1))\n",
        "    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n",
        "\n",
        "    index = list(np.argsort(distances)[:, :n_songs][0])\n",
        "\n",
        "    rec_songs = pandas_df.iloc[index]\n",
        "    rec_songs = rec_songs[~rec_songs['song_name'].isin(song_dict['song_name'])]\n",
        "    return rec_songs[metadata_cols].to_dict(orient='records')\n",
        "\n",
        "def recommend_songs_GMM(song_list, pandas_df, n_songs=10):\n",
        "\n",
        "    metadata_cols = ['song_name', 'artists','cluster_label', 'song_popularity',\n",
        " 'danceability',\n",
        " 'acousticness',\n",
        " 'instrumentalness',\n",
        " 'valence',\n",
        " 'tempo']\n",
        "    song_dict = dictionary_list(song_list)\n",
        "\n",
        "    song_center = find_mean(song_list, pandas_df)\n",
        "    scaler = gmm_pipeline.steps[0][1]\n",
        "    scaled_data = scaler.fit_transform(pandas_df[number_cols])\n",
        "    scaled_song_center = scaler.transform(song_center.reshape(1, -1))\n",
        "    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n",
        "    index = list(np.argsort(distances)[:, :n_songs][0])\n",
        "\n",
        "    rec_songs = pandas_df.iloc[index]\n",
        "    rec_songs = rec_songs[~rec_songs['song_name'].isin(song_dict['song_name'])]\n",
        "    return rec_songs[metadata_cols].to_dict(orient='records')\n",
        "\n",
        "visF=recommend_songs_FuzzyC([{'song_name': 'All of me', 'year': 2013}],pandas_df_fuzzy)\n",
        "visK=recommend_songs_Kmeans([{'song_name': 'All of me', 'year': 2013}],pandas_df_k)\n",
        "visG=recommend_songs_GMM([{'song_name': 'All of me', 'year': 2013}],pandas_df_gmm)"
      ],
      "metadata": {
        "id": "iNtc9gWM5KGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing Results"
      ],
      "metadata": {
        "id": "1CVkBaGc5VPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataVis(vis):\n",
        "    top10_genres = pd.DataFrame(vis)\n",
        "    top10_genres['danceability'] = top10_genres['danceability']*100\n",
        "    top10_genres['acousticness'] = top10_genres['acousticness']*100\n",
        "    top10_genres['valence'] = top10_genres['valence']*100\n",
        "    top10_genres['instrumentalness'] = top10_genres['instrumentalness']*100\n",
        "\n",
        "\n",
        "    fig = px.bar(top10_genres, x='song_name', y=['song_popularity','tempo','danceability','acousticness','valence','instrumentalness'], barmode='group')\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "P3D4sSD35Ral"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fuzzy C-Means"
      ],
      "metadata": {
        "id": "bZGlWaD_5aEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataVis(visF)"
      ],
      "metadata": {
        "id": "I3F8vlH65YfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### K-Means"
      ],
      "metadata": {
        "id": "2OrdfuGI5ibK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataVis(visK)"
      ],
      "metadata": {
        "id": "GMTrJ-B_5dk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gaussian Mixture Model"
      ],
      "metadata": {
        "id": "5nyykoJn5n1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataVis(visG)"
      ],
      "metadata": {
        "id": "GC4pR6nR5ghS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing Models"
      ],
      "metadata": {
        "id": "vg9e2t4e5r-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = ['Fuzzy C Means','KMeans', 'GMM']\n",
        "time_durations = [durationF, durationK, durationG]\n",
        "\n",
        "# create bar chart\n",
        "plt.bar(model_names, time_durations)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Time duration (seconds)')\n",
        "plt.title('Model time duration comparison')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L8DhzujY5qj4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}